{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rupamay/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import cv2, pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sqlite3\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "# classifier = tf.estimator.Estimator(model_dir=\"tmp/cnn_model2\", model_fn=cnn_model_fn)\n",
    "prediction = None\n",
    "model = load_model('cnn_model_keras3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size():\n",
    "    img = cv2.imread('gestures/42/100.jpg', 0)\n",
    "    return img.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "image_x, image_y = get_image_size()\n",
    "print(image_x,image_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def keras_process_image(img):\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (1, image_x, image_y, 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def keras_predict(model, image):\n",
    "    processed = keras_process_image(image)\n",
    "    pred_probab = model.predict(processed)[0]\n",
    "    pred_class = list(pred_probab).index(max(pred_probab))\n",
    "    return max(pred_probab), pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_pred_text_from_db(pred_class):\n",
    "    conn = sqlite3.connect(\"gesture_db.db\")\n",
    "    cmd = \"SELECT g_name FROM gesture WHERE g_id=\"+str(pred_class)\n",
    "    cursor = conn.execute(cmd)\n",
    "    for row in cursor:\n",
    "        return row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def split_sentence(text, num_of_words):\n",
    "    '''\n",
    "    Splits a text into group of num_of_words\n",
    "    '''\n",
    "    list_words = text.split(\" \")\n",
    "    length = len(list_words)\n",
    "    splitted_sentence = []\n",
    "    b_index = 0\n",
    "    e_index = num_of_words\n",
    "    while length > 0:\n",
    "        part = \"\"\n",
    "        for word in list_words[b_index:e_index]:\n",
    "            part = part + \" \" + word\n",
    "        splitted_sentence.append(part)\n",
    "        b_index += num_of_words\n",
    "        e_index += num_of_words\n",
    "        length -= num_of_words\n",
    "    return splitted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def put_splitted_text_in_blackboard(blackboard, splitted_text):\n",
    "    y = 200\n",
    "    for text in splitted_text:\n",
    "        cv2.putText(blackboard, text, (4, y), cv2.FONT_HERSHEY_TRIPLEX, 2, (255, 255, 255))\n",
    "        y += 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_hand_hist():\n",
    "    with open(\"hist3\", \"rb\") as f:\n",
    "        hist = pickle.load(f)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize():\n",
    "    \n",
    "    global prediction\n",
    "    cam = cv2.VideoCapture(1)\n",
    "    if cam.read()[0] == False:\n",
    "        cam = cv2.VideoCapture(0)\n",
    "    hist = get_hand_hist()\n",
    "    x, y, w, h = 300, 100, 300, 300\n",
    "    i=0\n",
    "    # create SIFT feature extractor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    text = \"\"\n",
    "    while True:\n",
    "        \n",
    "        text = \"\"\n",
    "        img = cam.read()[1]\n",
    "        img = cv2.flip(img, 1)\n",
    "        img = cv2.resize(img, (640, 480))\n",
    "        imgCrop = img[y:y+h, x:x+w]\n",
    "        imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([imgHSV], [0, 1], hist, [0, 180, 0, 256], 1)\n",
    "        disc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(16,16))\n",
    "        cv2.filter2D(dst,-1,disc,dst)\n",
    "        blur = cv2.bilateralFilter(dst, 9,100,75)\n",
    "        blur = cv2.GaussianBlur(dst, (11,11), 0)\n",
    "        blur = cv2.medianBlur(blur, 15)\n",
    "\n",
    "        thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "        thresh = cv2.merge((thresh,thresh,thresh))\n",
    "        thresh = cv2.cvtColor(thresh, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = thresh[y:y+h, x:x+w]\n",
    "        (openCV_ver,_,__) = cv2.__version__.split(\".\")\n",
    "        if openCV_ver=='3':\n",
    "            contours = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "        elif openCV_ver=='4':\n",
    "            contours = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "        if len(contours) > 0:\n",
    "            contour = max(contours, key = cv2.contourArea)\n",
    "            #print(cv2.contourArea(contour))\n",
    "            if cv2.contourArea(contour) > 10000:\n",
    "                x1, y1, w1, h1 = cv2.boundingRect(contour)\n",
    "                save_img = thresh[y1:y1+h1, x1:x1+w1]\n",
    "\n",
    "                if w1 > h1:\n",
    "                    save_img = cv2.copyMakeBorder(save_img, int((w1-h1)/2) , int((w1-h1)/2) , 0, 0, cv2.BORDER_CONSTANT, (0, 0, 0))\n",
    "                elif h1 > w1:\n",
    "                    save_img = cv2.copyMakeBorder(save_img, 0, 0, int((h1-w1)/2) , int((h1-w1)/2) , cv2.BORDER_CONSTANT, (0, 0, 0))\n",
    "                if i >= 4:\n",
    "                    save_img=cv2.equalizeHist(save_img)\n",
    "#                     cv2.imshow(\"save_img\", save_img)\n",
    "#                     save_img = cv2.resize(save_img, (image_x, image_y))\n",
    "\n",
    "                    pred_probab, pred_class = keras_predict(model, save_img)\n",
    "                    path_url='gestures/'+ str(pred_class) +'/1.jpg'\n",
    "                    img_gesture = cv2.imread(path_url,0)\n",
    "                    original_keypoints, original_descriptor = sift.detectAndCompute( img_gesture, None)\n",
    "                    query_keypoints, query_descriptor = sift.detectAndCompute(save_img,None)\n",
    "                    brute_force = cv2.BFMatcher(cv2.NORM_L2, crossCheck = True)\n",
    "                    matches = brute_force.match(original_descriptor, query_descriptor)\n",
    "#                   matches = sorted(matches, key = lambda x : x.distance)\n",
    "#                   result = cv2.drawMatches(img_gesture, original_keypoints, save_img, query_keypoints, matches, save_img, flags = 2)\n",
    "#                   cv2.imshow(\"result\",result)\n",
    "#                   print(\"The number of matching keypoints between the original and the query image is {}\\n\".format(len(matches)))\n",
    "\n",
    "                    if pred_probab*100 > 95 and len(matches)>=1:\n",
    "                        text = get_pred_text_from_db(pred_class)\n",
    "                        print(text)\n",
    "                    i=0\n",
    "                    \n",
    "                    \n",
    "                \n",
    "#                     cv2.imshow(\"save_img\", save_img)\n",
    "        i+=1\n",
    "        blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "#         splitted_text = split_sentence(text, 2)\n",
    "        \n",
    "#         put_splitted_text_in_blackboard(blackboard, splitted_text)\n",
    "        cv2.putText(blackboard, text, (30, 200), cv2.FONT_HERSHEY_TRIPLEX, 1.3, (255, 255, 255))\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        res = np.hstack((img, blackboard))\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"Recognizing gesture\", res)\n",
    "        cv2.imshow(\"thresh\", thresh)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "E\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "H\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "H\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "I/Me \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "I/Me \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "No\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "L\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "H\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "H\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "H\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "H\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Z\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Z\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Z\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Best of Luck \n"
     ]
    }
   ],
   "source": [
    "\n",
    "keras_predict(model, np.zeros((50, 50), dtype=np.uint8))\n",
    "recognize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
